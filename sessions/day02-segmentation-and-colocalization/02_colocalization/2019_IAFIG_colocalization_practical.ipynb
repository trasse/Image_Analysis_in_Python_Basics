{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Colocalisation Analysis with Python.\n",
    "\n",
    "\n",
    "Dominic Waithe 2019 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: To demonstrate and utilise the different colocalisation techniques.  Furthermore to use colocalisation to assess the quality of registration.\n",
    "\n",
    "Instructions:  \n",
    "Work through the notebook cell-by-cell. Where you see TODO, this means you need to do something. Optional TODO means you should do it if you are finding things too easy and have enough time.\n",
    "Many of the exercises below utilise the Skimage Python library, if in doubt, google the function names, to find out additional description.\n",
    "Some of the cells also involve plotting. If you are having trouble understanding the plotting with Matplotlib, then I recommend the following text: https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, img_as_float,color, img_as_ubyte\n",
    "from skimage import color, io\n",
    "from skimage.filters import threshold_otsu\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mander's test\n",
    "Exercise: We want to implement the Mander's test and calculate the value for the image.\n",
    "CHB = CH1 & CH2 (& is the 'and' operator. If a pixel is true in both images, it is true in the output CHB).\n",
    "M1 = CHB/CH1, M2 = CHB/CH2 (The Mander's coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Mander's example.\n",
    "img = io.imread('images/C5aR_LAMP-1_cell003.tif')\n",
    "\n",
    "\n",
    "#Convert image to float.\\\\\\\\\\\n",
    "img = img_as_float(img)\n",
    "#Split channels.\n",
    "img_dapi = img[:,:,2]\n",
    "img_ch1 = img[:,:,0]\n",
    "img_ch2 = img[:,:,1]\n",
    "\n",
    "#Calculate thresholds\n",
    "thr_ch1 = threshold_otsu(img_ch1)\n",
    "thr_ch2 = threshold_otsu(img_ch2)\n",
    "\n",
    "#Apply thresholds and generate binary images.\n",
    "binary_ch1 = img_ch1 > thr_ch1\n",
    "binary_ch2 = img_ch2 > thr_ch2\n",
    "\n",
    "binary_chB = binary_ch1 & binary_ch2\n",
    "\n",
    "\n",
    "#TODO:\n",
    "#Calculate the Mander's coefficient for the two channels. Note the formula's above in the description. \n",
    "#You will need to sum the pixels in each channel and then divide one by the other using the above formula\n",
    "#M1 = np.sum(binary_chB)/np.sum(binary_ch1)\n",
    "#M2 = np.sum(binary_chB)/np.sum(binary_ch2)\n",
    "\n",
    "#print(\"M1\",M1)\n",
    "#print(\"M2\",M2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(14, 4))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Raw image displayed as RGB image\", fontsize=12)\n",
    "ax[1].imshow(binary_ch1)\n",
    "ax[1].set_title(\"binary_ch1\", fontsize=12)\n",
    "ax[2].imshow(binary_ch2)\n",
    "ax[2].set_title(\"binary_ch2\", fontsize=12)\n",
    "ax[3].imshow(binary_chB)\n",
    "ax[3].set_title(\"binary_chB\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "We start with two lists of numbers (or two vectors or arrays as they are known). Please find the dot product of the two vectors. The dot product formula is a follows:<img src=\"src/dotProduct.png\">\n",
    "\n",
    "In python there is more than one way to find the dot product of two vectors. It can be performed using 'for loops' or through vectorised notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2,9,32,12,14,6,9,23,4,5,13,6,7,92,21,45];\n",
    "b = [7,21,4,2,92,9,9,6,13,12,45,5,6,23,14,32];\n",
    "\n",
    "#TODO:\n",
    "#Please calculate the dot product of the vectors 'a' and 'b'.\n",
    "#You may use any method you like. If get stuck. Check:\n",
    "#http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\n",
    "#If you rearrange the numbers in 'b', what sequence will give\n",
    "#the highest dot-product magnitude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pearson's test\n",
    "\n",
    "\n",
    "Exercise: See the similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example shows you how two number sequences can be compared with nothing more complicated than by using the dot product. This works as long as the sequences comprise of the same numbers but in a shuffled order.  To compare different sequences with the original we normalise by the magnitude of the vectors. To include this step. We use a more complicated equation:  \n",
    "\n",
    "<img src=\"src/eqn_full.gif\">\n",
    "\n",
    "https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\n",
    "https://en.wikipedia.org/wiki/Cross-correlation\n",
    "\n",
    "Hopefully you can see the top of this equation is very similar to the dot-product, except that it is centered on zero (subtraction of the mu, the mean) and the variance is normalised (division by standard deviation).\n",
    "\n",
    "Because the equation is normalised, a perfectly correlated sequence yeilds a rho value of 1.0. A perfectly random comparison yields 0 and two anti-correlated sequences will yield a value of -1.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's comparison of microscopy derived images\n",
    "In this image. We have channels in order 0) CFP-Gamma7 1) Dextran Far-Red 2) Bright-field channel 3) EEA1 Texas-Red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is an image which has 4 channels.\n",
    "\n",
    "img = io.imread('images/neuron.tif')\n",
    "print('image dimensions',img.shape, ' im dtype:',img.dtype)\n",
    "img = img_as_float(img)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(14, 4))\n",
    "ax[0].imshow(img[:,:,0],cmap='Blues_r')\n",
    "ax[0].set_title('CFP-Gamma7 ')\n",
    "ax[1].imshow(img[:,:,1],cmap='Greens_r')\n",
    "ax[1].set_title('Dextran Far-Red')\n",
    "ax[2].imshow(img[:,:,2],cmap='Greys_r')\n",
    "ax[2].set_title('Bright-field channel')\n",
    "ax[3].imshow(img[:,:,3],cmap='Reds_r')\n",
    "ax[3].set_title('EEA1 Texas-Red.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the Pearson's coefficent (rho) for the image channel 0, 3.\n",
    "X = img[:,:,0].flatten()\n",
    "Y = img[:,:,3].flatten()\n",
    "\n",
    "X_bar = np.average(X)\n",
    "Y_bar = np.average(Y)\n",
    "\n",
    "#TODO: Look at this equation. It should be the same as the one in the Pearson's text explanation text above. Complete the equation to unlock the treasure.\n",
    "rho = np.sum((X-X_bar)*(Y-Y_bar))/(np.sqrt(np.sum((X-X_bar)**2))*####Insert the remaining code here to finish the equation.\n",
    "#You should hopefully obtain a value 0.829\n",
    "print('rho',rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked image.\n",
    "You can threshold an image, preferably an independent channel, and then use this to mask your input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mask channel is a dextran dye which was injected into the cell.\n",
    "msk = img[:,:,1]\n",
    "#Lets threshold it with Otsu.\n",
    "thr_ch1 = threshold_otsu(msk)\n",
    "binary_mask = msk>thr_ch1\n",
    "\n",
    "#Now we want the pixel indices which are positive in the image.\n",
    "msk_indices = np.nonzero(binary_mask)\n",
    "\n",
    "#Calculate the Pearson's coefficent (rho) for the image channel 0, 3.\n",
    "X_m = img[msk_indices[0],msk_indices[1],0].flatten()\n",
    "Y_m = img[msk_indices[0],msk_indices[1],3].flatten()\n",
    "\n",
    "\n",
    "\n",
    "X_bar = np.average(X_m)\n",
    "Y_bar = np.average(Y_m)\n",
    "\n",
    "#TODO: Calculate Rho for these pixels.\n",
    "#What do you notice about the Pearson's coefficient value relative to the value calculated before (across all pixels).\n",
    "\n",
    "#You should hopefully obtain a value 0.677\n",
    "print('rho',rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = io.imread('images/composite.tif')\n",
    "img =  img_as_float(img)\n",
    "\n",
    "#The organisation of this file is not simple. It is also a 16-bit image.\n",
    "print(\"shape of img: \",img.shape,\"bit-depth: \",img.dtype)\n",
    "\n",
    "#We can assess the image data like so.\n",
    "CH0 = img[0,:,:]\n",
    "CH1 = img[1,:,:]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(14, 4))\n",
    "#Single channels visualisation can handle 16-bit\n",
    "ax[0].imshow(CH0,cmap='Greens_r')\n",
    "ax[0].set_title('CH0')\n",
    "ax[1].imshow(CH1,cmap='Reds_r');\n",
    "ax[1].set_title('CH1')\n",
    "#For the display, RGB needs to be three channel.\n",
    "imRGB = np.zeros((CH0.shape[0],CH0.shape[1],3))\n",
    "imRGB[:,:,0] = CH0\n",
    "imRGB[:,:,1] = CH1\n",
    "ax[2].imshow(imRGB);\n",
    "ax[2].set_title('RGB overlay');\n",
    "\n",
    "#TODO: What is the Pearson's value of this image comparing both its channels?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional TODO:\n",
    "#Exercise: The above image is not registered. \n",
    "#Can you devise a way of registering this image using the Pearson's test, as a measure for the similarity of the image in different positions. \n",
    "#hint you will need to move one of the images relative to the other and measure the colocalisation in this position. \n",
    "#The best localisation will have the highest rho value. Produce an image of your fully registered image.\n",
    "rho_max = 0\n",
    "#This moves one of your images with respect to the other.\n",
    "for c in range(1,40):\n",
    "    for r in range(1,40):\n",
    "        #We need to dynamically sample our image.\n",
    "        temp = CH0[c:-40+c,r:-40+r].reshape(-1);\n",
    "        #The -40 makes sure they are the same size.\n",
    "        ref = CH1[:-40,:-40].reshape(-1);\n",
    "        \n",
    "        rho = np.dot(temp-np.average(temp),ref-np.average(ref))/np.sqrt(((np.dot(temp-np.average(temp),temp-np.average(temp)))*np.dot(ref-np.average(ref),ref-np.average(ref))))\n",
    "        \n",
    "        #You will need to work out the highest rho value is recorded.\n",
    "        #You will then need to find the coordinates of this high rho.\n",
    "        #You will then need to provide a visualisation with the image translated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Optional TODO:\n",
    "#In the above example, the registration is done on the integer level. In normal situations we use subpixel precision location.\n",
    "#Repeat the above example using the following function to sample the pixels at a sub-pixel level.\n",
    "padded_CH0 = np.pad(CH0,20)#This time we pad. to accommodate the shifts within our image.\n",
    "padded_CH1 = np.pad(CH1,20)\n",
    "temp = padded_CH0 #template\n",
    "ref = padded_CH1.reshape(-1) #reference\n",
    "\n",
    "g_x, g_y = np.mgrid[0:padded_CH0.shape[0], 0:padded_CH0.shape[1]] #The coordinates of our image.\n",
    "grid_x, grid_y = np.mgrid[0:padded_CH0.shape[0]:1, 0:padded_CH0.shape[1]:1] #The grid which we want to sample.\n",
    "shift_x = 1.4 #You need to write for loops to apply different shifts\n",
    "shift_y = 20.5 \n",
    "shifted_img = scipy.interpolate.griddata(np.array([g_x.reshape(-1), g_y.reshape(-1)]).T,temp.reshape(-1), (grid_x+shift_x, grid_y+shift_y), method='linear',fill_value =0.0)\n",
    "simg = shifted_img.flatten()\n",
    "#You will need to work out the highest rho value is recorded.\n",
    "#You will then need to find the coordinates of this high rho.\n",
    "#You will then need to provide a visualisation with the image translated.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominic Waithe 2019 (c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
